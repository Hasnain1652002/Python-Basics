# -*- coding: utf-8 -*-
"""Language_Specification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sNvT11CouRTueTbsFkZhdVrKKuyONW74
"""

import re

operators = ["+","-","*","/","=","(",")",";","{","}"]
conditional_operators = ["!=","==",">=","<=",">","<"]
data_type = ["int"]
keywords = ["if ", "LOOP" , "print"]

code = """
         9.
         a9bc
         .59bcx
         .
         b9a

          """

def separate_elements(code):
  read = code.strip()
  lines = read.split("\n")
  line = [i.strip() for i in lines]
  return line


separate_elements(code)

def tokenize(code, separate_elements):
  token_list =[]
  statements = separate_elements(code)
  pattern = r'\b(int|[a-zA-Z_$][a-zA-Z0-9_$]*|\d+)\b|(\+\+|--|&&|\|\||[=<>!]=?|[+\-*/(),;{}])'
  for statement in statements:
    tokens = re.findall(pattern, statement)
    tokens = [token for group in tokens for token in group if token]
    token_list.append(tokens)
  return token_list


tokenize(code, separate_elements)

def lexical_Analyzer(code,separate_elements,tokenize):
  token_list = tokenize(code,separate_elements)
  for tokens in token_list:
    print(tokens)
    print("---------------------------------------------------------------------------------------------------")
    for token in tokens:
      if token in operators:
        print(f'Token Part:{token},    Class Part:{token}')
      if token in conditional_operators:
        print(f'Token Part:{token},    Class Part:{token}')
      if token in data_type:
        print(f'Token Part:{token} ,   Class Part: Data Type')
      if re.match(r'([_$a-zA-Z][_$a-zA-Z0-9]*)\s*',token) and token not in data_type and token not in keywords:
        print(f'Token Part:{token} ,   Class Part: Identifier')
      if re.match(r'^\d+$',token):
        print(f'Token Part:{token} ,   Class Part: Integer')
    print("---------------------------------------------------------------------------------------------------")

lexical_Analyzer(code,separate_elements,tokenize)

